spring:
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
        namespace: c8ae8be9-471e-4fa5-a5a0-9dfa8bc3d216   
  sleuth:
    sampler:
    #区间是0.1到1， 1代表保存所有的链路， 0.1表示保存10%的链路
      probability: 1
          #springCloudSleuth
  zipkin:
    baseUrl: http://127.0.0.1:9411/
    enabled: true
    sender:
      type: kafka
    service:
      name: search-service

  # es
  data:
  elasticsearch:
    rest:
      uris: [ "127.0.0.1:9200" ]
    elasticsearch:
      #集群名称
      cluster-name: docker-cluster 
      #配置es节点信息，逗号分隔，如果没有指定，则启动ClientNode
      cluster-nodes: 127.0.0.1:9300 
      properties:
        path:
          #elasticsearch日志存储目录
          logs: /home/aisys/logs/elasticsearch/log 
          #elasticsearch数据存储目录
          data: /home/aisys/logs/elasticsearch/data 

  # Kafka
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    #=============== consumer  =======================
    consumer:
      auto-commit-interval: 100
      auto-offset-reset: earliest
      group-id: search-group
      # true=自动提交；false=手动提交
      enable-auto-commit: false
    #=============== provider  =======================
    # all,-1,0,1 
    producer:
      acks: -1
      #批量发送消息字节数，默认值为16384
      batch-size: 16384
      #生产者可用于缓冲等待发送到服务器的记录的内存总字节数，默认值为33554432
      buffer-memory: 33554432
      retries: 0
      
      # Redis
  redis:
    host: 127.0.0.1
    port: 6379
    password: yoostar403
    timeout: 10000
    cache:
      expires: 1
      
#feign
feign: 
  sentinel: 
    enabled: true
  #feign调用超时时间配置，超过这个时间就熔断降级
  client:
    config:
      default:
        connectTimeout: 5000
        readTimeout: 5000
        loggerLevel: full

#redis序列化key
redis-key: xiyan